{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmMQh8bb-HNI"
      },
      "source": [
        "# Lab | Text Generation from Shakespeare's Sonnet\n",
        "\n",
        "This notebook explores the fascinating domain of text generation using a deep learning model trained on Shakespeare's sonnets.\n",
        "\n",
        "The objective is to create a neural network capable of generating text sequences that mimic the style and language of Shakespeare.\n",
        "\n",
        "By utilizing a Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) layers, this project aims to demonstrate how a model can learn and replicate the complex patterns of early modern English.\n",
        "\n",
        "The dataset used consists of Shakespeare's sonnets, which are preprocessed and tokenized to serve as input for the model.\n",
        "\n",
        "Throughout this notebook, you will see the steps taken to prepare the data, build and train the model, and evaluate its performance in generating text.\n",
        "\n",
        "This lab provides a hands-on approach to understanding the intricacies of natural language processing (NLP) and the potential of machine learning in creative text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrJHCVs2-HNK"
      },
      "source": [
        "Let's import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZA7uIsM-HNL"
      },
      "source": [
        "Let's get the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "id": "ymP2kDhk-HNM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/martin-gorner/tensorflow-rnn-shakespeare/master/shakespeare/sonnets.txt'\n",
        "resp = requests.get(url)\n",
        "with open('sonnets.txt', 'wb') as f:\n",
        "    f.write(resp.content)\n",
        "\n",
        "data = open('sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6oy-xPb-HNN"
      },
      "source": [
        "Step 1: Initialise a tokenizer and fit it on the corpus variable using .fit_on_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6A4JvoiT-HNO"
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN4BelDj-HNP",
        "outputId": "5be2baef-34fa-494d-8233-02e559ce9e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('and', 1), ('the', 2), ('to', 3), ('of', 4), ('my', 5), ('i', 6), ('in', 7), ('that', 8), ('thy', 9), ('thou', 10)]\n"
          ]
        }
      ],
      "source": [
        "# Show the first 10 words with their index\n",
        "print(list(tokenizer.word_index.items())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUoMgUiG-HNY"
      },
      "source": [
        "Step 2: Calculate the Vocabulary Size\n",
        "\n",
        "Let's figure out how many unique words are in your corpus. This will be the size of your vocabulary.\n",
        "\n",
        "Calculate the length of tokenizer.word_index, add 1 to it and store it in a variable called total_words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeuXkz0D-HNZ",
        "outputId": "bf2058e8-5996-41a9-c76a-3fae265f9121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 3375\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(f\"Vocabulary size: {total_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OykrEYlQ-HNa"
      },
      "source": [
        "Create an empty list called input_sequences.\n",
        "\n",
        "For each sentence in your corpus, convert the text into a sequence of integers using the tokenizer.\n",
        "Then, generate n-gram sequences from these tokens.\n",
        "\n",
        "Store the result in the list input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg961D4l-HNb",
        "outputId": "d4d590bf-4b9c-4735-b1bb-fef45fe3d73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 2], [3, 2, 313], [3, 2, 313, 1375], [3, 2, 313, 1375, 4], [118, 1376]]\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "    # Convert each line into a sequence of integers\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        # Generate n-grams for each sequence\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Print first few sequences for verification\n",
        "print(input_sequences[:5])  # Show the first 5 n-gram sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jvsRnN_-HNc"
      },
      "source": [
        "Calculate the length of the longest sequence in input_sequences. Assign the result to a variable called max_sequence_len.\n",
        "\n",
        "Now pad the sequences using pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre').\n",
        "Convert it to a numpy array and assign the result back to our variable called input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UACcIhxn-HNd",
        "outputId": "f08d1420-de32-4ba3-ed5e-42ed85547ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length: 11\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "# Find the length of the longest sequence\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "\n",
        "print(f\"Maximum sequence length: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsjlfFHH-HNe",
        "outputId": "fc54545a-3c7d-4225-edde-aad510b091d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded input shape: (15484, 11)\n"
          ]
        }
      ],
      "source": [
        "# Pad sequences to the same length\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "print(f\"Padded input shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-xCmoH--HNf"
      },
      "source": [
        "Prepare Predictors and Labels\n",
        "\n",
        "Split the sequences into two parts:\n",
        "\n",
        "- Predictors: All elements from input_sequences except the last one.\n",
        "- Labels: The last element of each sequence in input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68513d6f-9e03-4ae9-eabb-332a055b8e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predictors (X): (15484, 10)\n",
            "Shape of labels (y): (15484,)\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "# Split sequences into predictors (X) and labels (y)\n",
        "X = input_sequences[:, :-1]  # All columns except the last one\n",
        "y = input_sequences[:, -1]   # The last column only\n",
        "\n",
        "print(f\"Shape of predictors (X): {X.shape}\")\n",
        "print(f\"Shape of labels (y): {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IF7vDju-HNh",
        "outputId": "3f2f58cf-6355-4198-82fc-0fc519e96eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predictors (X): [[   0    0    0 ...    0    0    3]\n",
            " [   0    0    0 ...    0    3    2]\n",
            " [   0    0    0 ...    3    2  313]\n",
            " ...\n",
            " [   0    0    0 ... 3373  493  493]\n",
            " [   0    0    0 ...  493  493 3374]\n",
            " [   0    0    0 ...  493 3374   14]]\n",
            "Shape of labels (y): [   2  313 1375 ... 3374   14   15]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of predictors (X): {X}\")\n",
        "print(f\"Shape of labels (y): {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KceHjcT3-HNi"
      },
      "source": [
        "One-Hot Encode the Labels :\n",
        "\n",
        "Convert the labels (which are integers) into one-hot encoded vectors.\n",
        "\n",
        "Ensure the length of these vectors matches the total number of unique words in your vocabulary.\n",
        "\n",
        "Use ku.to_categorical() on labels with num_classes = total_words\n",
        "\n",
        "Assign the result back to our variable labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ilvGfCL-HNj",
        "outputId": "0619badb-f409-498d-8f7c-532633c3f0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one-hot encoded labels: (15484, 3375)\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "# One-hot encode the labels (y)\n",
        "y = ku.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "print(f\"Shape of one-hot encoded labels: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmQBthM8MPA8",
        "outputId": "417566a8-e8d5-4f5a-ceeb-d0d9d3a0f903"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_phK6jn-HNm"
      },
      "source": [
        "# Initialize the Model\n",
        "\n",
        "Start by creating a Sequential model.\n",
        "\n",
        "Add Layers to the Model:\n",
        "\n",
        "Embedding Layer: The first layer is an embedding layer. It converts word indices into dense vectors of fixed size (100 in this case). Set the input length to the maximum sequence length minus one, which corresponds to the number of previous words the model will consider when predicting the next word.\n",
        "\n",
        "Bidirectional LSTM Layer: Add a Bidirectional LSTM layer with 150 units. This layer allows the model to learn context from both directions (past and future) in the sequence. return_sequences=True\n",
        "\n",
        "Dropout Layer: Add a dropout layer with a rate of 0.2 to prevent overfitting by randomly setting 20% of the input units to 0 during training.\n",
        "\n",
        "LSTM Layer: Add a second LSTM layer with 100 units. This layer processes the sequence and passes its output to the next layer.\n",
        "\n",
        "Dense Layer (Intermediate): Add a dense layer with half the total number of words as units, using ReLU activation. A regularization term (L2) is added to prevent overfitting.\n",
        "\n",
        "Dense Layer (Output): The final dense layer has as many units as there are words in the vocabulary, with a softmax activation function to output a probability distribution over all words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hePbqqGm-HNn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDEylmiK-HNo",
        "outputId": "7c294014-6f86-4dfd-cfd7-5f240c4cd1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "\n",
        "    # Your code here :\n",
        "\n",
        "    # Embedding layer\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len - 1),\n",
        "\n",
        "    # Bidirectional LSTM layer\n",
        "    Bidirectional(LSTM(150, return_sequences=True)),\n",
        "\n",
        "    # Dropout layer\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Second LSTM layer\n",
        "    LSTM(100),\n",
        "\n",
        "    # Dense layer with ReLU activation\n",
        "    Dense(total_words // 2, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "\n",
        "    # Output Dense layer with Softmax activation\n",
        "    Dense(total_words, activation='softmax')\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "tBXjWX0I-HNp",
        "outputId": "4233e28c-b6d9-40da-f287-2d91cd81ec13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()  # Print the model structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iym046Ux-HNq"
      },
      "source": [
        "# Compile the Model:\n",
        "\n",
        "Compile the model using categorical crossentropy as the loss function, the Adam optimizer for efficient training, and accuracy as the metric to evaluate during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9lJo1dUe-HNr"
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8iWf-_7-HNs"
      },
      "source": [
        "# Print Model Summary:\n",
        "\n",
        "Use model.summary() to print a summary of the model, which shows the layers, their output shapes, and the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "93ikK7NM-HNs",
        "outputId": "56e4f806-79bb-4f1f-b80c-37007276cf7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Your code here :\n",
        "model.summary()  # Print the model structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "KLQ56IjV-HNt",
        "outputId": "d2e58ecf-9973-4bef-d9c4-5061a3b7fb04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m337,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │         \u001b[38;5;34m301,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m160,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1687\u001b[0m)                │         \u001b[38;5;34m170,387\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3375\u001b[0m)                │       \u001b[38;5;34m5,697,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">337,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">301,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1687</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">170,387</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3375</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,697,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,666,487\u001b[0m (25.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,666,487</span> (25.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,666,487\u001b[0m (25.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,666,487</span> (25.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Build the model with the specified input shape\n",
        "model.build(input_shape=(None, max_sequence_len - 1))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1jmtg1-HNu"
      },
      "source": [
        "# Now train the model for 50 epochs and assign it to a variable called history.\n",
        "\n",
        "Training the model with 50 epochs should get you around 40% accuracy.\n",
        "\n",
        "You can train the model for as many epochs as you like depending on the time and computing constraints you are facing. Ideally train it for a larger amount of epochs than 50.\n",
        "\n",
        "That way you will get better text generation at the end.\n",
        "\n",
        "However, dont waste your time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AIg2f1HBxqof",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34511381-2083-4c3d-f5ae-ac36fc7b5629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.0228 - loss: 7.3423\n",
            "Epoch 2/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0242 - loss: 6.5066\n",
            "Epoch 3/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0249 - loss: 6.4016\n",
            "Epoch 4/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0288 - loss: 6.2974\n",
            "Epoch 5/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.0357 - loss: 6.1953\n",
            "Epoch 6/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0363 - loss: 6.1568\n",
            "Epoch 7/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0411 - loss: 6.0569\n",
            "Epoch 8/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0430 - loss: 5.9953\n",
            "Epoch 9/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.0422 - loss: 5.9172\n",
            "Epoch 10/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.0458 - loss: 5.8735\n",
            "Epoch 11/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.0496 - loss: 5.7901\n",
            "Epoch 12/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.0534 - loss: 5.6850\n",
            "Epoch 13/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.0586 - loss: 5.6243\n",
            "Epoch 14/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.0601 - loss: 5.5568\n",
            "Epoch 15/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.0654 - loss: 5.4215\n",
            "Epoch 16/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0757 - loss: 5.3388\n",
            "Epoch 17/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0775 - loss: 5.2805\n",
            "Epoch 18/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.0842 - loss: 5.1606\n",
            "Epoch 19/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.0892 - loss: 5.0692\n",
            "Epoch 20/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.0947 - loss: 5.0058\n",
            "Epoch 21/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.1031 - loss: 4.8903\n",
            "Epoch 22/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.1111 - loss: 4.8057\n",
            "Epoch 23/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.1123 - loss: 4.7356\n",
            "Epoch 24/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.1257 - loss: 4.6173\n",
            "Epoch 25/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.1325 - loss: 4.5254\n",
            "Epoch 26/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.1382 - loss: 4.4480\n",
            "Epoch 27/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.1476 - loss: 4.3491\n",
            "Epoch 28/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.1584 - loss: 4.2797\n",
            "Epoch 29/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.1672 - loss: 4.2003\n",
            "Epoch 30/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.1844 - loss: 4.0811\n",
            "Epoch 31/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.2043 - loss: 3.9929\n",
            "Epoch 32/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2126 - loss: 3.9412\n",
            "Epoch 33/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.2269 - loss: 3.8461\n",
            "Epoch 34/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.2412 - loss: 3.7668\n",
            "Epoch 35/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.2500 - loss: 3.7427\n",
            "Epoch 36/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.2758 - loss: 3.6241\n",
            "Epoch 37/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.2869 - loss: 3.5665\n",
            "Epoch 38/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.3024 - loss: 3.4720\n",
            "Epoch 39/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.3203 - loss: 3.4149\n",
            "Epoch 40/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.3284 - loss: 3.3443\n",
            "Epoch 41/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.3395 - loss: 3.2936\n",
            "Epoch 42/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.3589 - loss: 3.2051\n",
            "Epoch 43/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.3786 - loss: 3.1477\n",
            "Epoch 44/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3852 - loss: 3.0919\n",
            "Epoch 45/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.3918 - loss: 3.0405\n",
            "Epoch 46/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.4154 - loss: 2.9480\n",
            "Epoch 47/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.4320 - loss: 2.9088\n",
            "Epoch 48/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.4394 - loss: 2.8697\n",
            "Epoch 49/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.4444 - loss: 2.8008\n",
            "Epoch 50/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.4563 - loss: 2.7563\n",
            "Epoch 51/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.4818 - loss: 2.6656\n",
            "Epoch 52/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.4898 - loss: 2.6420\n",
            "Epoch 53/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5019 - loss: 2.5731\n",
            "Epoch 54/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5145 - loss: 2.5403\n",
            "Epoch 55/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5162 - loss: 2.5089\n",
            "Epoch 56/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5204 - loss: 2.4962\n",
            "Epoch 57/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5402 - loss: 2.4102\n",
            "Epoch 58/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5483 - loss: 2.3721\n",
            "Epoch 59/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5629 - loss: 2.3099\n",
            "Epoch 60/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5735 - loss: 2.2713\n",
            "Epoch 61/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5742 - loss: 2.2609\n",
            "Epoch 62/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5904 - loss: 2.2113\n",
            "Epoch 63/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5898 - loss: 2.1913\n",
            "Epoch 64/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.5935 - loss: 2.1703\n",
            "Epoch 65/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6115 - loss: 2.1219\n",
            "Epoch 66/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6161 - loss: 2.0897\n",
            "Epoch 67/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6224 - loss: 2.0523\n",
            "Epoch 68/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6272 - loss: 2.0366\n",
            "Epoch 69/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.6386 - loss: 2.0002\n",
            "Epoch 70/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6525 - loss: 1.9252\n",
            "Epoch 71/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.6457 - loss: 1.9281\n",
            "Epoch 72/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.6618 - loss: 1.8903\n",
            "Epoch 73/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6565 - loss: 1.8880\n",
            "Epoch 74/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.6644 - loss: 1.8662\n",
            "Epoch 75/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6772 - loss: 1.8154\n",
            "Epoch 76/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6820 - loss: 1.7904\n",
            "Epoch 77/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.6875 - loss: 1.7683\n",
            "Epoch 78/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6947 - loss: 1.7257\n",
            "Epoch 79/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6948 - loss: 1.7379\n",
            "Epoch 80/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6959 - loss: 1.6989\n",
            "Epoch 81/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7079 - loss: 1.6903\n",
            "Epoch 82/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7083 - loss: 1.6514\n",
            "Epoch 83/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7065 - loss: 1.6448\n",
            "Epoch 84/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7116 - loss: 1.6163\n",
            "Epoch 85/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7166 - loss: 1.6132\n",
            "Epoch 86/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7210 - loss: 1.5782\n",
            "Epoch 87/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7300 - loss: 1.5439\n",
            "Epoch 88/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7286 - loss: 1.5471\n",
            "Epoch 89/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7337 - loss: 1.5286\n",
            "Epoch 90/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7350 - loss: 1.5173\n",
            "Epoch 91/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7405 - loss: 1.4883\n",
            "Epoch 92/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7476 - loss: 1.4799\n",
            "Epoch 93/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7461 - loss: 1.4561\n",
            "Epoch 94/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7609 - loss: 1.4213\n",
            "Epoch 95/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7549 - loss: 1.4156\n",
            "Epoch 96/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7551 - loss: 1.4167\n",
            "Epoch 97/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7619 - loss: 1.3966\n",
            "Epoch 98/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7665 - loss: 1.3672\n",
            "Epoch 99/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7597 - loss: 1.3846\n",
            "Epoch 100/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7658 - loss: 1.3646\n",
            "Epoch 101/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7652 - loss: 1.3599\n",
            "Epoch 102/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7732 - loss: 1.3182\n",
            "Epoch 103/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7608 - loss: 1.3482\n",
            "Epoch 104/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7773 - loss: 1.3102\n",
            "Epoch 105/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7703 - loss: 1.3382\n",
            "Epoch 106/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7739 - loss: 1.3063\n",
            "Epoch 107/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7837 - loss: 1.2549\n",
            "Epoch 108/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7783 - loss: 1.2863\n",
            "Epoch 109/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7852 - loss: 1.2563\n",
            "Epoch 110/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 1.2408\n",
            "Epoch 111/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7872 - loss: 1.2335\n",
            "Epoch 112/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7904 - loss: 1.2179\n",
            "Epoch 113/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 1.2080\n",
            "Epoch 114/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7898 - loss: 1.2103\n",
            "Epoch 115/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7919 - loss: 1.2059\n",
            "Epoch 116/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7976 - loss: 1.1869\n",
            "Epoch 117/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8010 - loss: 1.1744\n",
            "Epoch 118/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7987 - loss: 1.1716\n",
            "Epoch 119/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7993 - loss: 1.1752\n",
            "Epoch 120/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8008 - loss: 1.1624\n",
            "Epoch 121/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 1.1511\n",
            "Epoch 122/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8025 - loss: 1.1445\n",
            "Epoch 123/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8039 - loss: 1.1256\n",
            "Epoch 124/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7956 - loss: 1.1496\n",
            "Epoch 125/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 1.1345\n",
            "Epoch 126/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7995 - loss: 1.1384\n",
            "Epoch 127/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 1.1089\n",
            "Epoch 128/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 1.0904\n",
            "Epoch 129/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8146 - loss: 1.0839\n",
            "Epoch 130/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8136 - loss: 1.0809\n",
            "Epoch 131/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 1.0697\n",
            "Epoch 132/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 1.0602\n",
            "Epoch 133/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8123 - loss: 1.0645\n",
            "Epoch 134/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 1.0615\n",
            "Epoch 135/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8157 - loss: 1.0440\n",
            "Epoch 136/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8088 - loss: 1.0710\n",
            "Epoch 137/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8156 - loss: 1.0527\n",
            "Epoch 138/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8155 - loss: 1.0398\n",
            "Epoch 139/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8182 - loss: 1.0271\n",
            "Epoch 140/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8126 - loss: 1.0519\n",
            "Epoch 141/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 1.0348\n",
            "Epoch 142/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8166 - loss: 1.0258\n",
            "Epoch 143/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8282 - loss: 1.0021\n",
            "Epoch 144/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8207 - loss: 1.0175\n",
            "Epoch 145/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8251 - loss: 0.9952\n",
            "Epoch 146/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 1.0056\n",
            "Epoch 147/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8239 - loss: 0.9927\n",
            "Epoch 148/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8180 - loss: 1.0053\n",
            "Epoch 149/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8211 - loss: 0.9916\n",
            "Epoch 150/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8213 - loss: 0.9991\n",
            "Epoch 151/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.9850\n",
            "Epoch 152/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8252 - loss: 0.9735\n",
            "Epoch 153/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8303 - loss: 0.9661\n",
            "Epoch 154/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8267 - loss: 0.9606\n",
            "Epoch 155/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8291 - loss: 0.9548\n",
            "Epoch 156/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8264 - loss: 0.9710\n",
            "Epoch 157/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8204 - loss: 0.9780\n",
            "Epoch 158/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8294 - loss: 0.9508\n",
            "Epoch 159/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8324 - loss: 0.9397\n",
            "Epoch 160/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8259 - loss: 0.9557\n",
            "Epoch 161/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8287 - loss: 0.9455\n",
            "Epoch 162/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 0.9220\n",
            "Epoch 163/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.9558\n",
            "Epoch 164/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8305 - loss: 0.9216\n",
            "Epoch 165/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8264 - loss: 0.9375\n",
            "Epoch 166/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.9221\n",
            "Epoch 167/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8314 - loss: 0.9205\n",
            "Epoch 168/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8277 - loss: 0.9346\n",
            "Epoch 169/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8292 - loss: 0.9290\n",
            "Epoch 170/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8337 - loss: 0.9187\n",
            "Epoch 171/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8362 - loss: 0.9038\n",
            "Epoch 172/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8323 - loss: 0.9139\n",
            "Epoch 173/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8293 - loss: 0.9195\n",
            "Epoch 174/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8347 - loss: 0.9188\n",
            "Epoch 175/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8307 - loss: 0.9088\n",
            "Epoch 176/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8315 - loss: 0.9124\n",
            "Epoch 177/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8390 - loss: 0.8883\n",
            "Epoch 178/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8338 - loss: 0.8963\n",
            "Epoch 179/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8290 - loss: 0.9140\n",
            "Epoch 180/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8352 - loss: 0.8990\n",
            "Epoch 181/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8273 - loss: 0.9131\n",
            "Epoch 182/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8302 - loss: 0.9102\n",
            "Epoch 183/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8301 - loss: 0.8962\n",
            "Epoch 184/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8322 - loss: 0.8951\n",
            "Epoch 185/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8301 - loss: 0.9084\n",
            "Epoch 186/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8361 - loss: 0.8768\n",
            "Epoch 187/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8385 - loss: 0.8778\n",
            "Epoch 188/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8330 - loss: 0.8796\n",
            "Epoch 189/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8266 - loss: 0.9048\n",
            "Epoch 190/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 0.8671\n",
            "Epoch 191/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8339 - loss: 0.8752\n",
            "Epoch 192/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8376 - loss: 0.8631\n",
            "Epoch 193/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8377 - loss: 0.8595\n",
            "Epoch 194/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.8634\n",
            "Epoch 195/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8367 - loss: 0.8534\n",
            "Epoch 196/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8376 - loss: 0.8552\n",
            "Epoch 197/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8319 - loss: 0.8777\n",
            "Epoch 198/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8337 - loss: 0.8578\n",
            "Epoch 199/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8299 - loss: 0.8822\n",
            "Epoch 200/200\n",
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.8727\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BURh3Alw-HNw"
      },
      "source": [
        "# Use plt from matplotlib to plot the training accuracy over epochs and the loss over epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoMP3Ufn-HNw"
      },
      "source": [
        "First you will have to get the accuracy and loss data over epochs, you can do this by using methods on your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "40d0137e-c15d-4535-a62e-c76d17112db7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training accuracy and loss from the history\n",
        "accuracy = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "# Plot accuracy and loss together\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, accuracy, label='Accuracy', color='blue')\n",
        "plt.plot(epochs, loss, label='Loss', color='orange')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "metrics = model.evaluate(X, y, verbose=1)\n",
        "\n",
        "# Print the results\n",
        "for metric_name, metric_value in zip(model.metrics_names, metrics):\n",
        "    print(f\"{metric_name}: {metric_value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB0-Vv5NJSWX",
        "outputId": "f9af2e42-b6da-4822-c6c8-4e69e6108574"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8625 - loss: 0.7465\n",
            "loss: 0.7374\n",
            "compile_metrics: 0.8632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYquouqh-HNy"
      },
      "source": [
        "# Generate text with the model based on a seed text\n",
        "\n",
        "Now you will create two variables :\n",
        "\n",
        "- seed_text = 'Write the text you want the model to use as a starting point to generate the next words'\n",
        "- next_words = number_of_words_you_want_the_model_to_generate\n",
        "\n",
        "Please change number_of_words_you_want_the_model_to_generate by an actual integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHm4CrU1-HNy",
        "outputId": "a25d2bb5-70ac-42ec-e4ad-73a2130bd986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "love is too young to know what conscience is you so rare you hold it alone and die mine eye give me\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "\n",
        "# Seed text and number of words to generate\n",
        "seed_text = \"love is\"\n",
        "next_words = 20  # Adjust the number of words to generate\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]  # Get the index of the highest probability\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"Generated text:\")\n",
        "print(seed_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Test:\n",
        "\n",
        "# Seed text and number of words to generate\n",
        "seed_text = \"Sacrifice\"\n",
        "next_words = 10  # Adjust the number of words to generate\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]  # Get the index of the highest probability\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"Generated text:\")\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTsQff5-KyhT",
        "outputId": "17cd3901-9d2e-4630-cbd0-f01702e20d7f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "Sacrifice that i have frequent been with unknown minds lend the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third Test:\n",
        "\n",
        "# Seed text and number of words to generate\n",
        "seed_text = \"I am dying\"\n",
        "next_words = 5  # Adjust the number of words to generate\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]  # Get the index of the highest probability\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"Generated text:\")\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaP-sKM7LUcD",
        "outputId": "f9c0bcbe-d5e1-44b3-fd6e-440597aa9233"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "I am dying how i do not then\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1Vc8gh-HNz"
      },
      "source": [
        "Now create a loop that runs based on the next_words variable and generates new text based on your seed_text input string. Print the full text with the generated text at the end.\n",
        "\n",
        "This time you dont get detailed instructions.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990290f2-88e3-49dd-a87f-7d79193f5d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your seed text: My heart\n",
            "Enter the number of words to generate: 10\n",
            "\n",
            "Generated text:\n",
            "My heart doth plead that thou in him dost lie will bear\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "# Prompt the user for a seed text and number of words to generate\n",
        "seed_text = input(\"Enter your seed text: \")\n",
        "next_words = int(input(\"Enter the number of words to generate: \"))\n",
        "\n",
        "# Generate text\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"\\nGenerated text:\")\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5vcemj3-HN4"
      },
      "source": [
        "Experiment with at least 3 different seed_text strings and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bvUTQvG-HOO",
        "outputId": "5a01f065-1816-487f-e462-57c5471de1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your seed text: the light of the moon\n",
            "Enter the number of words to generate: 7\n",
            "\n",
            "Generated text:\n",
            "the light of the moon of things ill ill well ' grew\n"
          ]
        }
      ],
      "source": [
        "# Second Test :\n",
        "\n",
        "# Prompt the user for a seed text and number of words to generate\n",
        "seed_text = input(\"Enter your seed text: \")\n",
        "next_words = int(input(\"Enter the number of words to generate: \"))\n",
        "\n",
        "# Generate text\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"\\nGenerated text:\")\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third Test :\n",
        "\n",
        "# Prompt the user for a seed text and number of words to generate\n",
        "seed_text = input(\"Enter your seed text: \")\n",
        "next_words = int(input(\"Enter the number of words to generate: \"))\n",
        "\n",
        "# Generate text\n",
        "for _ in range(next_words):\n",
        "    # Tokenize the seed text\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "    # Pad the tokenized sequence\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "\n",
        "    # Convert index to word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word  # Append the predicted word to the seed text\n",
        "            break\n",
        "\n",
        "# Print the generated text\n",
        "print(\"\\nGenerated text:\")\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3smAMuMVPXUj",
        "outputId": "ed085b38-01d3-4d82-ee88-31f397db9136"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your seed text: Bloody night\n",
            "Enter the number of words to generate: 10\n",
            "\n",
            "Generated text:\n",
            "Bloody night o'er dearest not full of ill ' shall have your\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EXXkDz6Pp8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}